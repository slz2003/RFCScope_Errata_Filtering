================================================================================
SYSTEM PROMPT
================================================================================

You are ErrataPacketizer.
Input: an analyzer output containing router analysis and multiple expert analyses.
Task: produce deduplicated errata reports as structured JSON.

Constraints:
- Read the ENTIRE analysis carefully from start to finish. Do not skip any sections.
- Extract ALL issues mentioned anywhere in the analysis, including:
  * candidate issues (even if marked as "candidate" or "potential")
  * Expert-identified issues (even if experts conclude "no issue" or "editorial only")
  * Issues discussed in expert reasoning sections, even if not in formal issue lists
  * Any inconsistencies, ambiguities, or problems mentioned in any part of the text
  * Issues labeled as "potential", "candidate", "may cause", "underspecification", or similar
- Only use information present in the input text.
- Labels must be explicit and descriptive - clearly state what the problem is so readers understand it at a glance (include specific terms, values, or section references when relevant).
- Evidence snippets (5a) must be copied verbatim from the input text (without quotes). Snippets must be complete and sufficient - include all relevant context needed to understand and verify the issue. Do not use partial snippets.
- Evidence summary (5b) must be derived ONLY from the evidence snippets E1..En and must cite (E#) per bullet.
- Deduplicate: merge issues that refer to the same underlying erratum and list all experts.
- Severity/Confidence: prefer explicit expert values; otherwise infer conservatively and state "inferred".

================================================================================
USER PROMPT
================================================================================

Read the ENTIRE analyzer output below carefully from start to finish. Extract ALL issues, problems, inconsistencies, or ambiguities mentioned anywhere in the text.

Include ALL issues mentioned in the analysis:
- Router candidate issues (even if marked "candidate" or "potential")
- Expert-identified issues (check all expert sections: Scope, Causal, Quantitative, Structural, CrossRFC, Terminology, etc.)
- Issues discussed in expert reasoning/analysis sections, even if not in formal issue lists
- Any inconsistencies, ambiguities, underspecifications, or problems mentioned anywhere
- Issues labeled as "potential", "candidate", "may cause", "editorial", "underspecification", or similar
- Do NOT skip issues just because an expert concludes "no issue" or "editorial only" - if it's discussed, include it

Produce deduplicated errata reports as JSON.

Each errata report MUST contain exactly these fields:
1) label: Errata short Label (must be explicit and descriptive - readers should understand the problem at a glance, e.g., "Misnamed LDAP/X.509 CA certificate attribute ("caCertificate" vs "cACertificate")")
2) bug_type: Bug Type
3) explanation: Concise Explanation (1-2 sentences, neutral)
4) justification: Justification (array of bullets, must be supported by Evidence snippets)
5) evidence: Object with:
   - snippets: Array of {id: "E1", text: "..."} (verbatim, complete and sufficient excerpts, no quotes around text)
   - summary: Array of strings, each citing (E1), (E2), etc.
6) fix_direction: Fix Direction if exists, else null
7) severity: Low | Medium | High | Unspecified
8) severity_basis: Basis for severity
9) confidence: High | Medium | Low | Unspecified
10) experts: Array of "ExpertName: issue_id" strings

Constraints:
- Label must be explicit and descriptive - clearly state what the problem is so readers understand it at a glance (e.g., include specific terms, section references, or conflicting values when relevant).
- Evidence snippets must be verbatim from input (format: text directly, no quotes).
- Evidence snippets must be complete and sufficient - include all relevant context needed to understand the issue.
- Evidence summary must cite (E1), (E2), ... and contain no new facts beyond snippets.
- Keep each errata report concise.

Analyzer output:
<<<
================================================================================
COMPLETE ANALYSIS RESULT
================================================================================

RFC: Unknown
Section: Unknown
Model: gpt-5.1

================================================================================
ROUTER ANALYSIS
================================================================================
================================================================================
ROUTING SUMMARY
================================================================================

Excerpt Summary: Section 8 describes the security model for 0‑RTT data in TLS 1.3, the replay threats it poses, and three server-side mitigation strategies (single-use tickets, ClientHello recording with a replay cache, and freshness checks based on ticket age). It also sets client-side requirements about when 0‑RTT may be sent.
Overall Bug Likelihood: None

Dimensions:
  - Temporal: LOW - The section talks about windows and ticket lifetimes but does not define a concrete protocol state machine or ordering that appears inconsistent.
  - ActorDirectionality: LOW - Roles (client vs server, “server instance”, zones) are used consistently and align with the rest of the draft.
  - Scope: LOW - The text clearly scopes the anti-replay mechanisms as server-side choices and explains that clients cannot assume any particular mechanism; no obvious scope contradiction.
  - Causal: LOW - The causal chains (what happens if tickets or ClientHellos are replayed, or if state is or isn’t shared) are coherent and tie into earlier 0‑RTT text without introducing contradictions.
  - Quantitative: LOW - Ticket lifetimes, windows, and sequence-count style limits are described qualitatively; there are no hard numeric constraints here that conflict with other sections.
  - Deontic: LOW - The mix of MUST/SHOULD about per-instance acceptance, binder validation, and replay mitigation is internally consistent and compatible with related requirements in Sections 4.2.10 and 4.2.11.
  - Structural: LOW - No ABNF/YANG/field layouts are defined here; the prose references earlier-defined structures correctly.
  - CrossRFC: LOW - References to other sections of this draft (e.g., 2.3, 4.2.10, 4.2.11, 4.6.1, Appendix F.5/F.6) and to prior concepts (tickets, binders, ticket_age_add) appear correct and aligned.
  - Terminology: LOW - Terms like “0‑RTT data”, “ticket”, “ClientHello”, “PSK binder”, and “server instance” are used consistently with the rest of the document; “instance” is intentionally informal but not contradictory.
  - Boundary: LOW - Edge cases like freshly started servers, false positives in replay caches, and multi-zone deployments are explicitly discussed and handled at a high level; behavior is intentionally left flexible rather than undefined.

Candidate Issues: 1

  Issue 1:
    Type: None
    Label: 
    Relevant Dimensions: 
    Sketch: ...

Response ID: resp_0a53699d71db92da006958d498786c819484c9af7d27b27f9c


Vector Stores Used: vs_6958ce993c388191a7c9f32559e3b152
>>>

Return JSON array of errata reports:
{
  "reports": [
    {
      "label": "...",
      "bug_type": "...",
      "explanation": "...",
      "justification": ["...", "..."],
      "evidence": {
        "snippets": [
          {"id": "E1", "text": "..."}
        ],
        "summary": ["(E1) ...", "(E2) ..."]
      },
      "fix_direction": "..." or null,
      "severity": "...",
      "severity_basis": "...",
      "confidence": "...",
      "experts": ["..."]
    }
  ]
}