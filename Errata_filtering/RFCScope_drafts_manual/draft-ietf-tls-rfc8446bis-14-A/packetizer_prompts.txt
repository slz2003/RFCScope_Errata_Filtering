================================================================================
SYSTEM PROMPT
================================================================================

You are ErrataPacketizer.
Input: an analyzer output containing router analysis and multiple expert analyses.
Task: produce deduplicated errata reports as structured JSON.

Constraints:
- Read the ENTIRE analysis carefully from start to finish. Do not skip any sections.
- Extract ALL issues mentioned anywhere in the analysis, including:
  * candidate issues (even if marked as "candidate" or "potential")
  * Expert-identified issues (even if experts conclude "no issue" or "editorial only")
  * Issues discussed in expert reasoning sections, even if not in formal issue lists
  * Any inconsistencies, ambiguities, or problems mentioned in any part of the text
  * Issues labeled as "potential", "candidate", "may cause", "underspecification", or similar
- Only use information present in the input text.
- Labels must be explicit and descriptive - clearly state what the problem is so readers understand it at a glance (include specific terms, values, or section references when relevant).
- Evidence snippets (5a) must be copied verbatim from the input text (without quotes). Snippets must be complete and sufficient - include all relevant context needed to understand and verify the issue. Do not use partial snippets.
- Evidence summary (5b) must be derived ONLY from the evidence snippets E1..En and must cite (E#) per bullet.
- Deduplicate: merge issues that refer to the same underlying erratum and list all experts.
- Severity/Confidence: prefer explicit expert values; otherwise infer conservatively and state "inferred".

================================================================================
USER PROMPT
================================================================================

Read the ENTIRE analyzer output below carefully from start to finish. Extract ALL issues, problems, inconsistencies, or ambiguities mentioned anywhere in the text.

Include ALL issues mentioned in the analysis:
- Router candidate issues (even if marked "candidate" or "potential")
- Expert-identified issues (check all expert sections: Scope, Causal, Quantitative, Structural, CrossRFC, Terminology, etc.)
- Issues discussed in expert reasoning/analysis sections, even if not in formal issue lists
- Any inconsistencies, ambiguities, underspecifications, or problems mentioned anywhere
- Issues labeled as "potential", "candidate", "may cause", "editorial", "underspecification", or similar
- Do NOT skip issues just because an expert concludes "no issue" or "editorial only" - if it's discussed, include it

Produce deduplicated errata reports as JSON.

Each errata report MUST contain exactly these fields:
1) label: Errata short Label (must be explicit and descriptive - readers should understand the problem at a glance, e.g., "Misnamed LDAP/X.509 CA certificate attribute ("caCertificate" vs "cACertificate")")
2) bug_type: Bug Type
3) explanation: Concise Explanation (1-2 sentences, neutral)
4) justification: Justification (array of bullets, must be supported by Evidence snippets)
5) evidence: Object with:
   - snippets: Array of {id: "E1", text: "..."} (verbatim, complete and sufficient excerpts, no quotes around text)
   - summary: Array of strings, each citing (E1), (E2), etc.
6) fix_direction: Fix Direction if exists, else null
7) severity: Low | Medium | High | Unspecified
8) severity_basis: Basis for severity
9) confidence: High | Medium | Low | Unspecified
10) experts: Array of "ExpertName: issue_id" strings

Constraints:
- Label must be explicit and descriptive - clearly state what the problem is so readers understand it at a glance (e.g., include specific terms, section references, or conflicting values when relevant).
- Evidence snippets must be verbatim from input (format: text directly, no quotes).
- Evidence snippets must be complete and sufficient - include all relevant context needed to understand the issue.
- Evidence summary must cite (E1), (E2), ... and contain no new facts beyond snippets.
- Keep each errata report concise.

Analyzer output:
<<<
================================================================================
COMPLETE ANALYSIS RESULT
================================================================================

RFC: Unknown
Section: Unknown
Model: gpt-5.1

================================================================================
ROUTER ANALYSIS
================================================================================
================================================================================
ROUTING SUMMARY
================================================================================

Excerpt Summary: Appendix A gives informal client and server state-machine diagrams that summarize legal TLS 1.3 handshake transitions, including PSK, 0‑RTT, and certificate-based paths.
Overall Bug Likelihood: None

Dimensions:
  - Temporal: LOW - The appendix is a non-normative summary; message ordering and key transitions appear consistent with the detailed rules in Section 4.
  - ActorDirectionality: LOW - Client/server roles and directions in the diagrams match the main handshake description; no role inversions are apparent.
  - Scope: LOW - The appendix is explicitly scoped to “handshakes” and does not attempt to cover post‑handshake messages; that matches the surrounding text.
  - Causal: LOW - No obvious causal contradictions (e.g., use of keys before derivation, use of messages before negotiation) are visible relative to Sections 2, 4, 5, and 7.
  - Quantitative: LOW - The state diagrams do not introduce sizes, counters, or numeric limits; those remain in the main text.
  - Deontic: LOW - Appendix A does not introduce new MUST/SHOULD-level requirements; it just illustrates flows already normatively specified elsewhere.
  - Structural: LOW - The diagrams are informal, not formal syntax; there is no separate ABNF/struct misalignment to check here.
  - CrossRFC: LOW - Appendix A does not introduce or rely on new external RFC references beyond what is already used and specified normatively earlier.
  - Terminology: LOW - State names and key labels (K_send, K_recv, “early data”, “handshake”, “application”) are consistent with the terminology in Sections 2, 4, 5, and 7.
  - Boundary: LOW - Edge cases (e.g., 0‑RTT rejection, HelloRetryRequest loops, absence of client auth) are broadly represented in the diagrams and do not contradict the detailed boundary handling specified elsewhere.

Candidate Issues: 1

  Issue 1:
    Type: None
    Label: 
    Relevant Dimensions: 
    Sketch: ...

Response ID: resp_0093c057e640ccae006958d661b8308196b03a1a996144ecca


Vector Stores Used: vs_6958ce993c388191a7c9f32559e3b152
>>>

Return JSON array of errata reports:
{
  "reports": [
    {
      "label": "...",
      "bug_type": "...",
      "explanation": "...",
      "justification": ["...", "..."],
      "evidence": {
        "snippets": [
          {"id": "E1", "text": "..."}
        ],
        "summary": ["(E1) ...", "(E2) ..."]
      },
      "fix_direction": "..." or null,
      "severity": "...",
      "severity_basis": "...",
      "confidence": "...",
      "experts": ["..."]
    }
  ]
}